{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, re, urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import wget,gzip\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source and normalize movie / TV show data ##\n",
    "### IMdB ###\n",
    "- use batch interface: https://datasets.imdbws.com\n",
    "- subset the data based on a list of actors and titles\n",
    "\n",
    "### OMdB ###\n",
    "- use API : http://www.omdbapi.com/?i=tt3896198&apikey=xxx\n",
    "- the key is *imdb_id* so simple,  but rate limited to 1000 requests a day\n",
    "- attempt to source based on interesting titles subset from **IMdB**\n",
    "\n",
    "### TMdB ###\n",
    "- use API: https://api.themoviedb.org/3/movie/{id}   No limits.... but latency\n",
    "- the key is it's own... get batch file: https://developers.themoviedb.org/3/getting-started/daily-file-exports\n",
    "- join on *title* to **IMdB** subset to get wanted list to retrieve.  Result includes *imdb_id*\n",
    "\n",
    "### apple - includes cost data ###\n",
    "- use API: https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/iTuneSearchAPI/Searching.html#//apple_ref/doc/uid/TP40017632-CH5-SW1\n",
    "- this is rate limited to 20 calls per minute.  Hence sleep capability\n",
    "- add search, tconst and name back to data returned so it's simple to identify and join\n",
    "\n",
    "### boxofficemojo - includes boxoffice data ###\n",
    "- BeautifulSoup web scrape https://www.boxofficemojo.com/title/tt0021106/?ref_=bo_se_r_1\n",
    "- the tconst is included in the URL so simple to search...  just painful to scrape\n",
    "- add search and tconst to scraped data so it's easy to identify and join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import movies.utils\n",
    "\n",
    "# a bit of discipline on where files are and secrets...\n",
    "p = Path().cwd().joinpath(\"data\")\n",
    "with open (\"../apikeys.yaml\") as f: keys = yaml.safe_load(f)\n",
    "\n",
    "# l = 0 means just get.... so can use separete python process to be busy sourcing...\n",
    "l = 0\n",
    "    \n",
    "files = movies.utils.imdb.getdata(p)\n",
    "# regen subset...\n",
    "if False:\n",
    "    dfs = movies.utils.imdb.normalise(files, alldata=True, subsetdata=True)\n",
    "dfs = movies.utils.imdb.normalise(files, alldata=False, subsetdata=True)\n",
    "dfs, files = movies.utils.omdb.getandnormalise(keys[\"keys\"][\"omdb\"], dfs, files, path=p, limit=l)\n",
    "dfs, files = movies.utils.tmdb.getandnormalise(keys[\"keys\"][\"tmdb\"], dfs, files, path=p, limit=l)\n",
    "dfs, files = movies.utils.apple.getandnormalise(dfs, files, path=p, limit=l, sleep=3)\n",
    "dfs, files = movies.utils.mojo.getandnormalise(dfs, files, path=p, limit=l)\n",
    "\n",
    "# remind ourselves of available data...\n",
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Dark Knight\ttt0468569\t\n",
    "# Game of Throne tt0944947\n",
    "# for demo purpose - just pick first association when there are many\n",
    "mask = dfs[\"title.basics\"][\"tconst\"].isin([\"tt0468569\",\"tt0944947\"])\n",
    "mask = dfs[\"title.basics\"].index # everything... not reset_index() to make it good\n",
    "# mask = dfs[\"omdb.titles\"][\"Type\"]==\"movie\"\n",
    "\n",
    "# utility functions to understand source of data from column names\n",
    "def renamec(df, prefix=\"tbd_\", customExc=[]):\n",
    "    exc = [\"tconst\"] if len(customExc)==0 else customExc\n",
    "    proxy = {\"imdbID\":\"tconst\", \"imdb_id\":\"tconst\"}\n",
    "    return {\"columns\":{c:f\"{prefix}{c}\" if c not in proxy.keys() else proxy[c]\n",
    "                       for c in df.columns if c not in exc}}\n",
    "def cleandf(dfs, key, prefix, customExc=[]):\n",
    "    return dfs[key].rename(**renamec(dfs[key], prefix, customExc))\n",
    "\n",
    "demo = (dfs[\"title.basics\"].loc[mask]\n",
    " .rename(**renamec(dfs[\"title.basics\"], \"tb_\"))\n",
    " .merge(cleandf(dfs, \"omdb.titles\", \"omdb_\"), on=\"tconst\", how=\"left\")\n",
    " .merge(cleandf(dfs, \"title.ratings\", \"tr_\"), on=\"tconst\", how=\"left\")\n",
    " .merge(cleandf(dfs, \"title.akas\", \"alias_\").groupby(\"tconst\", as_index=False).first(), on=\"tconst\", how=\"left\")\n",
    " .merge(cleandf(dfs, \"title.crew\", \"crew_\").groupby(\"tconst\", as_index=False).first(), on=\"tconst\")\n",
    " .merge(cleandf(dfs, \"title.principals\", \"ppl_\").groupby(\"tconst\", as_index=False).first(), on=\"tconst\", how=\"left\")\n",
    " .merge(cleandf(dfs, \"title.episode\", \"ep_\", [\"x\"]).groupby(\"ep_parentTconst\", as_index=False).first(), \n",
    "        left_on=\"tconst\", right_on=\"ep_parentTconst\", how=\"left\")\n",
    " .merge(dfs[\"nmi\"]\n",
    "        .merge(cleandf(dfs, \"name.basics\", \"nb_\", [\"tconst\",\"nconst\"]), on=\"nconst\")\n",
    "        .groupby([\"tconst\"], as_index=False).first(), on=\"tconst\", suffixes=(\"\",\"_name\"))\n",
    " .merge(cleandf(dfs, \"tmdb.titles\", \"tmdb_\"), on=\"tconst\", how=\"left\")\n",
    "#  .merge(cleandf(dfs, \"titles.apple\", \"itunes_\").query(\"itunes_strongmatch==True\").groupby(\"tconst\", as_index=False).first(), on=\"tconst\", how=\"left\")\n",
    " .merge(cleandf(dfs, \"titles.apple\", \"itunes_\")\n",
    "        .sort_values([\"tconst\",\"itunes_strongmatch\",\"itunes_trackId\"], ascending=[True,False,True])\n",
    "        .groupby(\"tconst\", as_index=False).first(), on=\"tconst\", how=\"left\")\n",
    " .merge(cleandf(dfs, \"mojo.boxoffice\", \"mojo_\").groupby(\"tconst\", as_index=False).first(), on=\"tconst\", how=\"left\")\n",
    "\n",
    "\n",
    ")\n",
    "pd.options.display.max_rows=200\n",
    "pd.options.display.max_columns=200\n",
    "cols = movies.utils.util.catcolumns(demo)\n",
    "(demo\n",
    "#  .dropna(subset=[\"tb_genres\"])\n",
    "#  .query(\"tb_genres.str.contains('Romance') & tb_genres.str.contains('Comedy')\")\n",
    "#  .sort_values([\"itunes_trackPrice\",\"mojo_AllWorldwide\"], ascending=False)\n",
    " .sort_values([\"mojo_AllWorldwide\"], ascending=False)\n",
    " .loc[:,cols.query(\"~type.isin(['url','artwork','list'])\").index]\n",
    " .head(5)\n",
    "#  .to_html(p.joinpath(\"rc.html\"), index=False)\n",
    "\n",
    ")\n",
    "# TODO beautifulsoup it to insert <div> elements so don't need javascript enabled browser\n",
    "# with open(p.joinpath(\"rc.html\"), \"a\") as f, open(p.parent.parent.joinpath(\"inject.html\")) as f2: \n",
    "#     f.write(f2.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data quality ###\n",
    "1. what columns are URLs / links to files\n",
    "2. what columns are USD but as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs[\"titles.apple\"].query(\"tconst=='tt0499549'\")\n",
    "# dfs[\"tmdb.titles\"].query(\"imdb_id=='tt0499549'\")\n",
    "\n",
    "movies.utils.util.catcolumns(dfs[\"mojo.boxoffice\"]).query(\"type=='float64'\").index.tolist()\n",
    "moneycols=['AllDomestic','AllInternational','AllWorldwide','Domestic','International','Worldwide','Opening','Budget','Domestic Opening']\n",
    "badlist = dfs[\"mojo.boxoffice\"].query(\"~search.str.endswith('credits/')\").groupby([\"tconst\"]).agg({c:lambda x: x.isna().all() for c in moneycols})\n",
    "# badlist = dfs[\"mojo.boxoffice\"].groupby([\"tconst\"]).agg({c:lambda x: x.isna().all() for c in moneycols})\n",
    "\n",
    "bt = badlist.T.all().to_frame().rename(columns={0:\"notok\"}).query(\"notok\")\n",
    "bt = (bt.merge(dfs[\"title.ratings\"], on=\"tconst\")\n",
    "      .merge(dfs[\"title.basics\"], on=\"tconst\")\n",
    "      .sort_values([\"startYear\",\"numVotes\"], ascending=[False, False])\n",
    "      .query(\"numVotes>10000 and startYear>=1975 and runtimeMinutes>=60\")\n",
    "     )\n",
    "bt\n",
    "# di = dfs[\"mojo.boxoffice\"].loc[dfs[\"mojo.boxoffice\"][\"tconst\"].isin(bt[\"tconst\"])].index\n",
    "# di\n",
    "# dfs[\"mojo.boxoffice\"].drop(di, inplace=True)\n",
    "# dfs[\"mojo.boxoffice\"].reset_index(drop=True).to_json(files[\"mojo.boxoffice\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    dfr = pd.read_csv(p.joinpath(\"title.ratings.tsv.gz\"), sep=\"\\t\").replace({\"\\\\N\":np.nan})\n",
    "    mask = ~dfr[\"tconst\"].isin(dfs[\"title.basics\"][\"tconst\"])\n",
    "#     dfr.loc[mask,].sort_values([\"numVotes\",\"averageRating\"], ascending=False).head(10)\n",
    "\n",
    "    pd.concat([pd.read_json(p.joinpath(\"wanted.json\")),\n",
    "               dfr.loc[mask,].sort_values([\"numVotes\",\"averageRating\"], ascending=False).head(20)\n",
    "              ]).drop_duplicates().reset_index(drop=True).to_json(p.joinpath(\"wanted.json\"), orient=\"records\")\n",
    "\n",
    "with open(p.joinpath(\"wanted.json\")) as f: tm = json.load(f)\n",
    "print(len(tm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(3,2, figsize=[20,10],\n",
    "                      sharey=False, sharex=False, gridspec_kw={\"hspace\":0.3})\n",
    "\n",
    "# REVENUE percentiles\n",
    "(demo.dropna(subset=[\"tb_startYear\",\"mojo_AllWorldwide\"])\n",
    " .groupby(\"tb_startYear\")\n",
    " .agg({\"mojo_AllWorldwide\":[np.median, lambda x: np.percentile(x, q=95),lambda x: np.percentile(x, q=5)]})\n",
    " .droplevel(0, axis=1)\n",
    " .rename(columns={\"<lambda_0>\":\"95th\",\"<lambda_1>\":\"5th\"})\n",
    " .plot(ax=ax[0][0])\n",
    ")\n",
    "ax[0][0].set_xlabel(\"Worldwide revenue\", weight='bold', fontsize=12)\n",
    "\n",
    "# TITLES summary\n",
    "various = ['tvEpisode','short','tvShort','tvSpecial','video','videoGame','tvMovie','tvMiniSeries']\n",
    "(demo.dropna(subset=[\"tb_startYear\",\"tb_titleType\",\"tb_primaryTitle\"])\n",
    "#  .query(\"~tb_titleType.isin(['tvEpisode','short','tvShort','tvSpecial','video','videoGame','tvMovie','tvMiniSeries'])\")\n",
    " .assign(decade=lambda x: np.where(x[\"tb_startYear\"]<1970, 1960, (x[\"tb_startYear\"]//10)*10),\n",
    "        tb_titleType=lambda x: np.where(x[\"tb_titleType\"].isin(various), \"various\", x[\"tb_titleType\"]))\n",
    " .groupby([\"tb_titleType\",\"decade\"])\n",
    " .agg({\"tb_primaryTitle\":[\"count\"]})\n",
    " .unstack(0)\n",
    " .droplevel([0,1], axis=1)\n",
    " .plot(ax=ax[0][1], kind=\"bar\")\n",
    ")\n",
    "ax[0][1].set_xlabel(\"Titles by decade\", weight='bold', fontsize=12)\n",
    "for tick in ax[0][1].get_xticklabels(): tick.set_rotation(0)\n",
    "\n",
    "# WORLDWIDE revenu\n",
    "cap = 1.75e9\n",
    "cap = np.percentile(demo[\"mojo_AllWorldwide\"].dropna(), q=99.9)\n",
    "(demo.dropna(subset=[\"mojo_AllWorldwide\",\"itunes_trackPrice\",\"tr_numVotes\"])\n",
    " .assign(tb_startYear=lambda x: np.where(x[\"tb_startYear\"]<2000, 2000, x[\"tb_startYear\"]).astype(\"float64\"),\n",
    "        itunes_trackPrice=lambda x: x[\"itunes_trackPrice\"].astype(\"float64\"))\n",
    " .assign(mojo_AllWorldwide=lambda x: np.where(x[\"mojo_AllWorldwide\"]>cap,cap,x[\"mojo_AllWorldwide\"]))\n",
    " .plot(ax=ax[1][1], x=\"mojo_AllWorldwide\", y=\"tr_numVotes\", s=\"itunes_trackPrice\", c=\"tb_startYear\", kind=\"scatter\", colormap=\"jet\")\n",
    ")\n",
    "ax[1][1].set_xlabel(f\"revenue vs votes, year and price Limit:{cap/1e9:.2f}B\", weight='bold', fontsize=12)\n",
    "\n",
    "# iTunes price\n",
    "(demo.dropna(subset=[\"tb_startYear\",\"itunes_trackPrice\"])\n",
    " .groupby(\"tb_startYear\")\n",
    " .agg({\"itunes_trackPrice\":[np.median, lambda x: np.percentile(x, q=95),lambda x: np.percentile(x, q=5)]})\n",
    " .droplevel(0, axis=1)\n",
    " .rename(columns={\"<lambda_0>\":\"95th\",\"<lambda_1>\":\"5th\"})\n",
    " .plot(ax=ax[1][0])\n",
    ")\n",
    "ax[1][0].set_xlabel(\"iTunes price\", weight='bold', fontsize=12)\n",
    "\n",
    "# ATTRIBUTE summary\n",
    "(pd.concat([dfs[k].count().to_frame().rename(columns={0:k}) for k in dfs.keys()])\n",
    " .T.plot(ax=ax[2][0], kind=\"barh\", stacked=True)\n",
    ")\n",
    "ax[2][0].get_legend().remove()\n",
    "ax[2][0].set_xlabel(f\"Attribute Summary\", weight='bold', fontsize=12)\n",
    "\n",
    "# MARKET revenue\n",
    "cap = np.percentile(dfs[\"mojo.boxoffice\"][\"Worldwide\"].dropna(), q=90)\n",
    "df = (dfs[\"mojo.boxoffice\"].dropna(subset=[\"Worldwide\",\"Markets\"])\n",
    " .merge(cleandf(dfs, \"title.ratings\", \"tr_\"), on=\"tconst\", how=\"left\")\n",
    " .assign(Markets=lambda x: x[\"Markets\"].str.replace(\"^([0-9]+)(.*)$\",r\"Multi \\2\"))\n",
    " .assign(MarketsF=lambda x: pd.factorize(x[\"Markets\"])[0].astype(\"float64\"))\n",
    "# rebase so it's in same range as number of markets\n",
    " .assign(tr_numVotes=lambda x: (x[\"tr_numVotes\"]/x[\"tr_numVotes\"].max())*x[\"MarketsF\"].max() )\n",
    " .merge(dfs[\"title.basics\"], on=\"tconst\")\n",
    " .assign(startYear=lambda x: np.where(x[\"startYear\"]<2000, 2000, x[\"startYear\"]).astype(\"float64\"))\n",
    " .assign(Worldwide=lambda x: np.where(x[\"Worldwide\"]>cap,cap,x[\"Worldwide\"]))\n",
    " \n",
    ")\n",
    "df.plot(ax=ax[2][1], kind=\"scatter\", y=\"MarketsF\", x=\"Worldwide\", c=\"startYear\", s=\"tr_numVotes\", colormap=\"jet\")\n",
    "# build table to decode y-axis\n",
    "dft = (df.groupby([\"MarketsF\",\"Markets\"], as_index=False)[\"Worldwide\"]\n",
    "       .count()\n",
    "       .sort_values(\"MarketsF\", ascending=True)\n",
    "       .reset_index(drop=True)\n",
    "       .assign(Markets=lambda x: x.apply(lambda r: f'{r.Markets} ({r.Worldwide})', axis=1))\n",
    "       .drop(columns=\"Worldwide\")\n",
    "       .astype(\"int64\", errors=\"ignore\")\n",
    "      )\n",
    "dft = pd.concat([dft.loc[i*10:(i*10)+9].reset_index(drop=True) for i in range(7)], axis=1)\n",
    "ax[2][1].set_xlabel(f\"Market vs Revenue. Colour:Year, Size:Votes Limit:{cap/1e6:.2f}M\", weight='bold', fontsize=12)\n",
    "ax[2][1].table(dft.values,\n",
    "        colWidths=[0.02,.14] * 7,\n",
    "         bbox=[0, -0.65, (0.02+.14)*7, 0.4],\n",
    "        cellLoc=\"left\"\n",
    "        )\n",
    "# MARKET revenue *end*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, figsize=[20,5],\n",
    "                      sharey=False, sharex=False, gridspec_kw={\"hspace\":0.5})\n",
    "\n",
    "\n",
    "cap = .1e9\n",
    "cap = np.percentile(dfs[\"mojo.boxoffice\"][\"Worldwide\"].dropna(), q=90)\n",
    "df = (dfs[\"mojo.boxoffice\"].dropna(subset=[\"Worldwide\",\"Markets\"])\n",
    " .merge(cleandf(dfs, \"title.ratings\", \"tr_\"), on=\"tconst\", how=\"left\")\n",
    " .assign(Markets=lambda x: x[\"Markets\"].str.replace(\"^([0-9]+)(.*)$\",r\"Multi \\2\"))\n",
    " .assign(MarketsF=lambda x: pd.factorize(x[\"Markets\"])[0].astype(\"float64\"))\n",
    "# rebase so it's in same range as number of markets\n",
    " .assign(tr_numVotes=lambda x: (x[\"tr_numVotes\"]/x[\"tr_numVotes\"].max())*x[\"MarketsF\"].max() )\n",
    " .merge(dfs[\"title.basics\"], on=\"tconst\")\n",
    " .assign(startYear=lambda x: np.where(x[\"startYear\"]<2000, 2000, x[\"startYear\"]).astype(\"float64\"))\n",
    " .assign(Worldwide=lambda x: np.where(x[\"Worldwide\"]>cap,cap,x[\"Worldwide\"]))\n",
    " \n",
    ")\n",
    "df.plot(ax=ax, kind=\"scatter\", y=\"MarketsF\", x=\"Worldwide\", c=\"startYear\", s=\"tr_numVotes\", colormap=\"jet\")\n",
    "# build table to decode y-axis\n",
    "dft = (df.groupby([\"MarketsF\",\"Markets\"], as_index=False)[\"Worldwide\"]\n",
    "       .count()\n",
    "       .sort_values(\"MarketsF\", ascending=True)\n",
    "       .reset_index(drop=True)\n",
    "       .assign(Markets=lambda x: x.apply(lambda r: f'{r.Markets} ({r.Worldwide})', axis=1))\n",
    "       .drop(columns=\"Worldwide\")\n",
    "       .astype(\"int64\", errors=\"ignore\")\n",
    "      )\n",
    "dft = pd.concat([dft.loc[i*10:(i*10)+9].reset_index(drop=True) for i in range(7)], axis=1)\n",
    "ax.set_xlabel(f\"Market vs Revenue. Colour:Year, Size:Votes Limit:{cap/1e6:.2f}M\", weight='bold', fontsize=12)\n",
    "ax.table(dft.values,\n",
    "        colWidths=[0.02,.14] * 7,\n",
    "         bbox=[0, -0.55, (0.02+.14)*7, 0.4],\n",
    "        cellLoc=\"left\"\n",
    "        )\n",
    "\n",
    "# dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=[20,5],\n",
    "                      sharey=False, sharex=False, gridspec_kw={\"hspace\":0.5})\n",
    "\n",
    "\n",
    "(pd.concat([dfs[k].count().to_frame().rename(columns={0:k}) for k in dfs.keys()])\n",
    " .T.plot(ax=ax, kind=\"barh\", stacked=True)\n",
    ")\n",
    "ax.get_legend().remove()\n",
    "ax.set_xlabel(f\"Attribute Summary\", weight='bold', fontsize=12)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
